{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from IPython.display import clear_output\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/df_comments.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Test and Fit Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting test size to a finite number so that all train/test splits are the same size\n",
    "test_size = int(len(df) * .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['comments_text_lemma'],\n",
    "                                                   df['target'],\n",
    "                                                   test_size = test_size,\n",
    "                                                   random_state = 42)\n",
    "\n",
    "X = df['comments_text_lemma']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame() \n",
    "df_test['comments'] = X_test\n",
    "df_test['target'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression Standard TfidfVectorizer\n",
    "Default: 0.70 CV Score\n",
    "\n",
    "New Best: 0.74 CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the pipeline\n",
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7589\n",
      "Best parameters: {'logreg__C': 600, 'logreg__solver': 'liblinear', 'tvec__ngram_range': (1, 3)}\n",
      "GS Train Score: 1.0\n",
      "GS Test Score: 0.6875\n",
      "Cross Val Score: 0.7346\n",
      "\n",
      "                   Pred Neg (Lib)  Pred Pos (Cons)\n",
      "Actual Neg (Lib)   63              54             \n",
      "Actual Pos (Cons)  31              124            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### The following code (and all ensuing blocks) run a GridSearchCV on the models that were identified\n",
    "#### as having strong CrossVal Scores in the EDA stage. \n",
    "params = {\n",
    "    'tvec__ngram_range' : [(1,1), (1,3)],\n",
    "    'logreg__solver' : ['liblinear'],\n",
    "    'logreg__C' : [500, 600, 800],\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3, n_jobs=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best score:',round(gs.best_score_, 4))\n",
    "print('Best parameters:',gs.best_params_)\n",
    "print('GS Train Score:',round(gs.score(X_train, y_train), 4))\n",
    "print('GS Test Score:',round(gs.score(X_test, y_test), 4))\n",
    "print('Cross Val Score:',round(cross_val_score(gs, X, y, cv=5).mean(), 4))\n",
    "predictions = gs.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, columns=['Pred Neg (Lib)', 'Pred Pos (Cons)'],\n",
    "                 index=['Actual Neg (Lib)', 'Actual Pos (Cons)'])\n",
    "print(f'\\n{cm_df}\\n')\n",
    "df_test['logreg_predictions'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Multinomial Naive Bayes Count Vectorized\n",
    "Default: 0.71 CV Score\n",
    "\n",
    "New Best: .71 Best Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('bag', BaggingClassifier(base_estimator=MultinomialNB()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7234\n",
      "Best parameters: {'bag__base_estimator__alpha': 0.1, 'bag__max_samples': 0.8, 'cvec__ngram_range': (1, 5)}\n",
      "GS Train Score: 0.9706\n",
      "GS Test Score: 0.6912\n",
      "Cross Val Score: 0.7108\n",
      "\n",
      "                   Pred Neg (Lib)  Pred Pos (Cons)\n",
      "Actual Neg (Lib)   74              43             \n",
      "Actual Pos (Cons)  41              114            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'cvec__ngram_range' : [(1,1), (1,3), (1,5)],\n",
    "    'bag__base_estimator__alpha' : [0.1, 1.0], ## Iterating through the base estimate (MultinomialNB)\n",
    "    'bag__max_samples' : [.5, .8, .95]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3, n_jobs=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best score:',round(gs.best_score_, 4))\n",
    "print('Best parameters:',gs.best_params_)\n",
    "print('GS Train Score:',round(gs.score(X_train, y_train), 4))\n",
    "print('GS Test Score:',round(gs.score(X_test, y_test), 4))\n",
    "print('Cross Val Score:',round(cross_val_score(gs, X, y, cv=5).mean(), 4))\n",
    "predictions = gs.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, columns=['Pred Neg (Lib)', 'Pred Pos (Cons)'],\n",
    "                 index=['Actual Neg (Lib)', 'Actual Pos (Cons)'])\n",
    "print(f'\\n{cm_df}\\n')\n",
    "df_test['nb_predictions'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier Standard TfidfVectorizer Model\n",
    "Default: 0.71 CV Score\n",
    "\n",
    "New Best: 0.70 Best Score\n",
    "\n",
    "NOTES: Not sure why I can't replicate the 0.71 CV Score. Likely has to do with the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.705\n",
      "Best parameters: {}\n",
      "GS Train Score: 0.9192\n",
      "GS Test Score: 0.6801\n",
      "Cross Val Score: 0.697\n",
      "\n",
      "                   Pred Neg (Lib)  Pred Pos (Cons)\n",
      "Actual Neg (Lib)   54              63             \n",
      "Actual Pos (Cons)  24              131            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "#     'tvec__ngram_range' : [(1,1)],\n",
    "#     'tvec__max_df' : [.8, .9, 1.0],\n",
    "#     'gb__n_estimators' : [40, 50],\n",
    "#     'gb__max_depth' : [3],\n",
    "#     'gb__max_features' : [0.9, 1.0],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3, n_jobs=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best score:',round(gs.best_score_, 4))\n",
    "print('Best parameters:',gs.best_params_)\n",
    "print('GS Train Score:',round(gs.score(X_train, y_train), 4))\n",
    "print('GS Test Score:',round(gs.score(X_test, y_test), 4))\n",
    "print('Cross Val Score:',round(cross_val_score(gs, X, y, cv=5).mean(), 4))\n",
    "predictions = gs.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, columns=['Pred Neg (Lib)', 'Pred Pos (Cons)'],\n",
    "                 index=['Actual Neg (Lib)', 'Actual Pos (Cons)'])\n",
    "print(f'\\n{cm_df}\\n')\n",
    "df_test['gb_predictions'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression TfidVector (LSA)\n",
    "Default: .71 CV score\n",
    "\n",
    "New Best: 0.71 CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words='english', min_df=5, max_df=.8)\n",
    "\n",
    "term_mat = tvec.fit_transform(df['comments_text_lemma'])\n",
    "term_df = pd.DataFrame(term_mat.toarray(), columns=tvec.get_feature_names())\n",
    "\n",
    "SVD = TruncatedSVD(n_components=100)\n",
    "svd_matrix = SVD.fit_transform(term_df)\n",
    "\n",
    "component_names = [\"component_\"+str(i+1) for i in range(100)]\n",
    "svd_df = pd.DataFrame(svd_matrix,\n",
    "                      columns=component_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(svd_df,\n",
    "                                                    df['target'],\n",
    "                                                    test_size = test_size,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X = svd_df\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7246\n",
      "Best parameters: {'logreg__C': 1.0, 'logreg__fit_intercept': False, 'logreg__penalty': 'l2', 'logreg__solver': 'liblinear'}\n",
      "GS Train Score: 0.7772\n",
      "GS Test Score: 0.6949\n",
      "Cross Val Score: 0.7089\n",
      "\n",
      "                   Pred Neg (Lib)  Pred Pos (Cons)\n",
      "Actual Neg (Lib)   61              56             \n",
      "Actual Pos (Cons)  27              128            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'logreg__solver' : ['liblinear'],\n",
    "    'logreg__C' : [1.0],\n",
    "    'logreg__fit_intercept' : [True, False],\n",
    "    'logreg__penalty' : ['l1', 'l2']\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3, n_jobs=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Best score:',round(gs.best_score_, 4))\n",
    "print('Best parameters:',gs.best_params_)\n",
    "print('GS Train Score:',round(gs.score(X_train, y_train), 4))\n",
    "print('GS Test Score:',round(gs.score(X_test, y_test), 4))\n",
    "print('Cross Val Score:',round(cross_val_score(gs, X, y, cv=5).mean(), 4))\n",
    "predictions = gs.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, columns=['Pred Neg (Lib)', 'Pred Pos (Cons)'],\n",
    "                 index=['Actual Neg (Lib)', 'Actual Pos (Cons)'])\n",
    "print(f'\\n{cm_df}\\n')\n",
    "df_test['lsa_logreg_predictions'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Combination\n",
    "\n",
    "Notes: Well, I learned a lot. But this was only marginally useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['combo'] = df_test['logreg_predictions'] + df_test['nb_predictions'] + df_test['lsa_logreg_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_preds = []\n",
    "for i in df_test.index:\n",
    "    if df_test['combo'][i] >= 2:\n",
    "        combo_preds.append(1)\n",
    "    else:\n",
    "        combo_preds.append(0)\n",
    "df_test['combo_preds'] = combo_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg Score: 0.6875\n",
      "Logreg LSA Score: 0.6948529411764706\n",
      "NB Score: 0.6911764705882353\n",
      "Combo Score: 0.6911764705882353\n"
     ]
    }
   ],
   "source": [
    "print('Logreg Score:',accuracy_score(df_test['target'], df_test['logreg_predictions']))\n",
    "print('Logreg LSA Score:',accuracy_score(df_test['target'], df_test['lsa_logreg_predictions']))\n",
    "print('NB Score:',accuracy_score(df_test['target'], df_test['nb_predictions']))\n",
    "print('Combo Score:',accuracy_score(df_test['target'], df_test['combo_preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
